{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009e8fc2",
   "metadata": {},
   "source": [
    "# 1. Build your own convolutional neural network using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ee2e8",
   "metadata": {},
   "source": [
    "Define the `NeuralNet` model, which is a customizable convolutional neural network designed for image classification tasks. \n",
    "\n",
    "It has a sequence of convolutional layers with optional pooling layers for feature extraction, followed by a series of fully connected layers for classification. We can adjust the number and configuration of hidden layers and pooling operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fb46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ec4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_hiddens: List[int], \n",
    "        poolings: List[bool], \n",
    "        n_classes: int\n",
    "    ):\n",
    "        assert len(n_hiddens) == len(poolings)\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_hiddens: List[int] = n_hiddens\n",
    "        self.poolings: List[bool] = poolings\n",
    "        self.n_classes: int = n_classes\n",
    "\n",
    "        feature_extractor_modules: List[nn.Module] = []\n",
    "        for n_hidden, pooling in zip(n_hiddens, poolings):\n",
    "            feature_extractor_modules.extend([\n",
    "                nn.LazyConv2d(out_channels=n_hidden, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(num_features=n_hidden),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            if pooling:\n",
    "                feature_extractor_modules.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(*feature_extractor_modules)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.LazyLinear(out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.feature_extractor(x)\n",
    "        y = self.classifier(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4961e0f",
   "metadata": {},
   "source": [
    "# 2. Train your model using dog heart dataset (you may need to use  Google Colab (or Kaggle) with GPU to train your code) \n",
    "\n",
    "### (1) use torchvision.datasets.ImageFolder for the training dataset\n",
    "### (2) use custom dataloader for test dataset (return image tensor and file name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e73b2",
   "metadata": {},
   "source": [
    "### Utility classes:\n",
    "Define `Accumulator` class to track performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133be475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "from typing import Optional, Dict, TextIO, Any\n",
    "from collections import defaultdict\n",
    "import datetime as dt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b50215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    \"\"\"\n",
    "    A utility class for accumulating values for multiple metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.__records: defaultdict[str, float] = defaultdict(float)\n",
    "\n",
    "    def add(self, **kwargs: Any) -> None:\n",
    "        \"\"\"\n",
    "        Add values to the accumulator.\n",
    "\n",
    "        Parameters:\n",
    "            - **kwargs: named metric and the value is the amount to add.\n",
    "        \"\"\"\n",
    "        metric: str\n",
    "        value: float\n",
    "        for metric, value in kwargs.items():\n",
    "            # Each keyword argument represents a metric name and its value to be added\n",
    "            self.__records[metric] += value\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reset the accumulator by clearing all recorded metrics.\n",
    "        \"\"\"\n",
    "        self.__records.clear()\n",
    "\n",
    "    def __getitem__(self, key: str) -> float:\n",
    "        \"\"\"\n",
    "        Retrieve a record by key.\n",
    "\n",
    "        Parameters:\n",
    "            - key (str): The record key name.\n",
    "\n",
    "        Returns:\n",
    "            - float: The record value.\n",
    "        \"\"\"\n",
    "        return self.__records[key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67036d3",
   "metadata": {},
   "source": [
    "Define `EarlyStopping` to early stop the training process given on some validation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267754d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    A simple early stopping utility to terminate training when a monitored metric stops improving.\n",
    "\n",
    "    Attributes:\n",
    "        - patience (int): The number of epochs with no improvement after which training will be stopped.\n",
    "        - tolerance (float): The minimum change in the monitored metric to qualify as an improvement,\n",
    "        - considering the direction of the metric being monitored.\n",
    "        - bestscore (float): The best score seen so far.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int, tolerance: float = 0.) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the EarlyStopping instance.\n",
    "        \n",
    "        Parameters:\n",
    "            - patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "            - tolerance (float): The minimum change in the monitored metric to qualify as an improvement. \n",
    "            Defaults to 0.\n",
    "        \"\"\"\n",
    "        self.patience: int = patience\n",
    "        self.tolerance: float = tolerance\n",
    "        self.bestscore: float = float('inf')\n",
    "        self.__counter: int = 0\n",
    "\n",
    "    def __call__(self, value: float) -> None:\n",
    "        \"\"\"\n",
    "        Update the state of the early stopping mechanism based on the new metric value.\n",
    "\n",
    "        Parameters:\n",
    "            - value (float): The latest value of the monitored metric.\n",
    "        \"\"\"\n",
    "        # Improvement or within tolerance, reset counter\n",
    "        if value <= self.bestscore + self.tolerance:\n",
    "            self.bestscore: float = value\n",
    "            self.__counter: int = 0\n",
    "\n",
    "        # No improvement, increment counter\n",
    "        else:\n",
    "            self.__counter += 1\n",
    "\n",
    "    def __bool__(self) -> bool:\n",
    "        \"\"\"\n",
    "        Determine if the training process should be stopped early.\n",
    "\n",
    "        Returns:\n",
    "            - bool: True if training should be stopped (patience exceeded), otherwise False.\n",
    "        \"\"\"\n",
    "        return self.__counter >= self.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427e8d5",
   "metadata": {},
   "source": [
    "Define `Logger` class to log the training process to file and console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df22a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "\n",
    "    \"\"\"\n",
    "    A class used to log the training process.\n",
    "\n",
    "    This class provides methods to log messages to a file and the console. \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        logfile: str = f\".log/{dt.datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    ) -> None:\n",
    "    \n",
    "        \"\"\"\n",
    "        Initialize the logger.\n",
    "\n",
    "        Parameters:\n",
    "            - logfile (str, optional): The path to the logfile. \n",
    "            Defaults to a file in the .log directory with the current timestamp.\n",
    "        \"\"\"\n",
    "        self.logfile: pathlib.Path = pathlib.Path(logfile)\n",
    "        os.makedirs(name=self.logfile.parent, exist_ok=True)\n",
    "        self._file: TextIO = open(self.logfile, mode='w')\n",
    "\n",
    "    def log(\n",
    "        self, \n",
    "        epoch: int, \n",
    "        n_epochs: int, \n",
    "        batch: Optional[int] = None, \n",
    "        n_batches: Optional[int] = None, \n",
    "        took: Optional[float] = None, \n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Log a message to console and a log file\n",
    "\n",
    "        Parameters:\n",
    "            - epoch (int): The current epoch.\n",
    "            - n_epochs (int): The total number of epochs.\n",
    "            - batch (int, optional): The current batch. Defaults to None.\n",
    "            - n_batches (int, optional): The total number of batches. Defaults to None.\n",
    "            - took (float, optional): The time it took to process the batch or epoch. Defaults to None.\n",
    "            - **kwargs: Additional metrics to log.\n",
    "        \"\"\"\n",
    "        suffix: str = ', '.join([f'{metric}: {value:.3e}' for metric, value in kwargs.items()])\n",
    "        prefix: str = f'Epoch {epoch}/{n_epochs} | '\n",
    "        if batch is not None:\n",
    "            prefix += f'Batch {batch}/{n_batches} | '\n",
    "        if took is not None:\n",
    "            prefix += f'Took {took:.2f}s | '\n",
    "        logstring: str = prefix + suffix\n",
    "        print(logstring)\n",
    "        self._file.write(logstring + '\\n')\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        \"\"\"\n",
    "        Close the logfile at garbage collected.\n",
    "        \"\"\"\n",
    "        self._file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a5228",
   "metadata": {},
   "source": [
    "Define `CheckPointSaver` to save model's checkpoints during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9841a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckPointSaver:\n",
    "    \"\"\"\n",
    "    A class used to save PyTorch model checkpoints.\n",
    "\n",
    "    Attributes:\n",
    "        - dirpath (pathlib.Path): The directory where the checkpoints are saved.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dirpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the CheckPointSaver.\n",
    "\n",
    "        Parameters:\n",
    "            - dirpath (os.PathLike): The directory where the checkpoints are saved.\n",
    "        \"\"\"\n",
    "        self.dirpath: pathlib.Path = pathlib.Path(dirpath)\n",
    "        os.makedirs(name=self.dirpath, exist_ok=True)\n",
    "\n",
    "    def save(self, model: nn.Module, filename: str) -> None:\n",
    "        \"\"\"\n",
    "        Save checkpoint to a .pt file.\n",
    "\n",
    "        Parameters:\n",
    "            - model (nn.Module): The PyTorch model to save.\n",
    "            - filename (str): the checkpoint file name\n",
    "        \"\"\"\n",
    "        torch.save(obj=model, f=os.path.join(self.dirpath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29a5e4",
   "metadata": {},
   "source": [
    "### `Dataset` classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb1f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564831d5",
   "metadata": {},
   "source": [
    "Define `DogHeartLabeledDataset` class for labeled dataset (training and validation), this class extends the `ImageFolder` from `torchvision`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5ad8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHeartLabeledDataset(ImageFolder):\n",
    "\n",
    "    #extend\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize((128, 128)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        super().__init__(root=data_root, transform=self.transformation)\n",
    "        self.data_root: str = data_root\n",
    "\n",
    "        self.filepaths: List[str] = [path for path, _ in self.samples]\n",
    "        self.filenames: List[str] = [path.split('/')[-1] for path in self.filepaths]\n",
    "        self.labels: List[int] = [label for _, label in self.samples]\n",
    "\n",
    "    #extend\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int, str]:\n",
    "        tensor: torch.Tensor; label: int\n",
    "        tensor, label = super().__getitem__(idx)\n",
    "        filename: str = self.filenames[idx]\n",
    "        return tensor, label, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78dbee",
   "metadata": {},
   "source": [
    "Define `DogHeartUnlabeledDataset` class for unlabeled dataset (testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56607d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHearUnlabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.data_root: str = data_root\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize((128, 128)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        self.filenames: List[str] = os.listdir(self.data_root)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, str]:\n",
    "        filename: str = self.filenames[idx]\n",
    "        image: Image = Image.open(os.path.join(self.data_root, filename))\n",
    "        tensor: torch.Tensor = self.transformation(image)\n",
    "        return tensor, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fcd66",
   "metadata": {},
   "source": [
    "Create dataloaders from labeled datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed68234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "valid_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efd80a",
   "metadata": {},
   "source": [
    "Define the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd24f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3cd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(\n",
    "    scores: torch.Tensor,\n",
    "    gt_labels: torch.Tensor,\n",
    "):\n",
    "    return F.cross_entropy(input=scores, target=gt_labels, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92701546",
   "metadata": {},
   "source": [
    "Specify the computing device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebb8b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0807991",
   "metadata": {},
   "source": [
    "Define the `evaluation` function to report the accuracy and data loss over a batched dataset (dataloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdce575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, dataloader: DataLoader) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    metrics = Accumulator()\n",
    "\n",
    "    # Loop through each batch\n",
    "    for batch, (batch_images, gt_labels, filenames) in enumerate(dataloader, start=1):\n",
    "        batch_images = batch_images.to(device)\n",
    "        gt_labels = gt_labels.to(device)\n",
    "        scores: torch.Tensor = model(batch_images)\n",
    "        pred_labels = scores.max(dim=1).indices\n",
    "        n_corrects = (pred_labels == gt_labels).sum().item()\n",
    "        n_predictions = pred_labels.numel()\n",
    "        loss = loss_function(scores, gt_labels).mean()\n",
    "\n",
    "        # Accumulate the metrics\n",
    "        metrics.add(n_corrects=n_corrects, n_predictions=n_predictions, loss=loss.item())\n",
    "\n",
    "    # Compute the aggregate metrics\n",
    "    accuracy: float = metrics['n_corrects'] / metrics['n_predictions']\n",
    "    loss: float = metrics['loss'] / batch\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87249365",
   "metadata": {},
   "source": [
    "Define the `train` function that implements the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe0e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    n_epochs: int,\n",
    "    patience: int,\n",
    "    tolerance: float,\n",
    "    checkpoint_dir: Optional[str] = None,\n",
    ") -> nn.Module:\n",
    "\n",
    "    model.train()\n",
    "    train_metrics = Accumulator()\n",
    "    early_stopping = EarlyStopping(patience, tolerance)\n",
    "    logger = Logger()\n",
    "    checkpoint_saver = CheckPointSaver(dirpath=checkpoint_dir)\n",
    "\n",
    "    # loop through each epoch\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Loop through each batch\n",
    "        for batch, (batch_images, gt_labels, filenames) in enumerate(train_dataloader, start=1):\n",
    "            batch_images = batch_images.to(device)\n",
    "            gt_labels = gt_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            scores: torch.Tensor = model(batch_images)\n",
    "            pred_labels: torch.Tensor = scores.max(dim=1).indices\n",
    "            # print(pred_labels.detach().cpu().numpy())\n",
    "            # print(gt_labels.detach().cpu().numpy())\n",
    "            n_corrects: int = (pred_labels == gt_labels).sum().item()\n",
    "            n_predictions: int = pred_labels.numel()\n",
    "            loss: torch.Tensor = loss_function(scores, gt_labels).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate the metrics\n",
    "            train_metrics.add(n_correct=n_corrects, n_predictions=n_predictions, loss=loss.item())\n",
    "            train_accuracy: float = train_metrics['n_correct'] / train_metrics['n_predictions']\n",
    "            train_loss = train_metrics['loss'] / batch\n",
    "            logger.log(\n",
    "                epoch=epoch, n_epochs=n_epochs, batch=batch, n_batches=len(train_dataloader),\n",
    "                train_accuracy=train_accuracy, train_loss=train_loss\n",
    "            )\n",
    "\n",
    "        # Save checkpoint\n",
    "        if checkpoint_dir:\n",
    "            checkpoint_saver.save(model, filename=f'epoch{epoch}.pt')\n",
    "\n",
    "        # Reset metric records for next epoch\n",
    "        train_metrics.reset()\n",
    "\n",
    "        # Evaluate\n",
    "        val_accuracy, val_loss = evaluate(model=model, dataloader=val_dataloader)\n",
    "        logger.log(epoch=epoch, n_epochs=n_epochs, val_accuracy=val_accuracy, val_loss=val_loss)\n",
    "        print('='*20)\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping:\n",
    "            print('Early Stopped')\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda634a",
   "metadata": {},
   "source": [
    "Create an instance of `NeuralNet`, which is a Convolutional Neural Network. \n",
    "\n",
    "Its feature extractor consists of 9 convolutional layers with hidden dimensions progressively increasing from 512 to 2048. Pooling layers are applied after every third convolutional layer to reduce spatial dimensions. \n",
    "\n",
    "The feature extractor is followed by a classifier with fully connected layers predicting three output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ee3acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/katz_dnn_project_one/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet(\n",
    "    n_hiddens=[\n",
    "        512, 512, 512, \n",
    "        1024, 1024, 1024, \n",
    "        2048, 2048, 2048,\n",
    "    ], \n",
    "    poolings=[\n",
    "        True, False, False, \n",
    "        True, False, False, \n",
    "        True, False, False,\n",
    "    ],\n",
    "    n_classes=3,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5a858",
   "metadata": {},
   "source": [
    "Create an instance of Adam optimizer, which has the learning rate adaptively changing from `0.00001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0ec9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(params=net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d500c0",
   "metadata": {},
   "source": [
    "Now we run the training loop on the maximum number of `100` epochs. \n",
    "\n",
    "After each epoch, the model is evaluated on the validation dataset. The early stopping is implemented to stop the training process if the validation loss does not improve after `10` consecutive epochs. The tolerance of the improvement is set to `0`. This early stopping helps avoid overfitting.\n",
    "\n",
    "The checkpoints are saved after each epoch in the `.pt` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "516a897c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.checkpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, n_epochs, patience, tolerance, checkpoint_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m loss_function(scores, gt_labels)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 33\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Accumulate the metrics\u001b[39;00m\n\u001b[1;32m     36\u001b[0m train_metrics\u001b[38;5;241m.\u001b[39madd(n_correct\u001b[38;5;241m=\u001b[39mn_corrects, n_predictions\u001b[38;5;241m=\u001b[39mn_predictions, loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/conda/envs/katz_dnn_project_one/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/katz_dnn_project_one/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/conda/envs/katz_dnn_project_one/lib/python3.11/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/conda/envs/katz_dnn_project_one/lib/python3.11/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/katz_dnn_project_one/lib/python3.11/site-packages/torch/optim/adam.py:581\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    579\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    584\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB. GPU "
     ]
    }
   ],
   "source": [
    "net = train(\n",
    "    model=net,\n",
    "    train_dataloader=DataLoader(dataset=train_dataset, batch_size=16, shuffle=True),\n",
    "    val_dataloader=DataLoader(dataset=valid_dataset, batch_size=4, shuffle=False),\n",
    "    optimizer=optimizer,\n",
    "    n_epochs=100,\n",
    "    patience=10,\n",
    "    tolerance=0.,\n",
    "    checkpoint_dir='.checkpoints',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63262f",
   "metadata": {},
   "source": [
    "# 3. Evaluate your model using the developed software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437136c",
   "metadata": {},
   "source": [
    "Define the `predict` function to evaluate the model on test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9df13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: nn.Module, dataloader: DataLoader) -> pd.DataFrame:\n",
    "    model.eval()\n",
    "\n",
    "    filenames = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, fnames in dataloader:\n",
    "            images = images.to(next(model.parameters()).device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            filenames.extend(fnames)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    prediction_table = pd.DataFrame(\n",
    "        data={'image': filenames, 'label': predictions}\n",
    "    )\n",
    "    prediction_table.to_csv(\n",
    "        f'{dt.datetime.now().strftime(r\"%Y%m%d%H%M%S\")}.csv', \n",
    "        header=False, \n",
    "        index=False\n",
    "    )\n",
    "    return prediction_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522a2b2",
   "metadata": {},
   "source": [
    "Load the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687038bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint: str = '.checkpoints/epoch14.pt'\n",
    "\n",
    "trained_model: NeuralNet = torch.load(last_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee238394",
   "metadata": {},
   "source": [
    "Evaluate the model on test dataset. A `.csv` file is output to load to the developed software:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdacebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DogHearUnlabeledDataset(data_root='Dog_heart/Test')\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=16, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563674d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model=trained_model, dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fdec95",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/hiepdang-ml/dog_heart_classification/blob/master/test.png?raw=true\" alt=\"PredictionImage\" style=\"width:50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5846bc",
   "metadata": {},
   "source": [
    "# 4. Compare results with [RVT paper](https://www.nature.com/articles/s41598-023-50063-x). Requirement: performance is better than VGG16: 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d454ff",
   "metadata": {},
   "source": [
    "We got `71%` accuracy on test dataset, which is better than `VGG16`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f12835",
   "metadata": {},
   "source": [
    "# 5. Write a four-page paper report using the shared LaTex template. Upload your paper to ResearchGate or Arxiv, and put your paper link and GitHub weight link here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1379e9f",
   "metadata": {},
   "source": [
    "Paper: `...`\n",
    "\n",
    "Source code: https://github.com/hiepdang-ml/dog_heart_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476372c",
   "metadata": {},
   "source": [
    "# 6. Grading rubric\n",
    "\n",
    "(1). Code ------- 20 points (you also need to upload your final model as a pt file)\n",
    "\n",
    "(2). Grammer ---- 20 points\n",
    "\n",
    "(3). Introduction & related work --- 10 points\n",
    "\n",
    "\n",
    "(4). Method  ---- 20 points\n",
    "\n",
    "(5). Results ---- 20 points\n",
    "\n",
    "     > = 70 % -->10 points\n",
    "     < 50 % -->0 points\n",
    "     >= 50 % & < 70% --> 0.5 point/percent\n",
    "     \n",
    "\n",
    "(6). Discussion - 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445593c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
